{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T20:04:12.934625Z",
     "start_time": "2024-06-28T20:03:42.468103Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "read user yaml files: 0it [00:00, ?it/s]\n",
      "/gscratch/efml/jpgard/miniconda3/envs/rtfm/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8c3b1ad23b4f899ba3d05019ea754f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "WARNING:root:adding special tokens {} to vocab\n",
      "WARNING:root:adding tokens {'eoc_token': '<|endcompletion|>', 'qa_sep_token': '<|endinput|>', 'ans_choices_sep_token': '||'} to vocab (as special tokens=True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from llama_recipes.inference.model_utils import load_model\n",
    "\n",
    "from rtfm.configs import TrainConfig, TokenizerConfig\n",
    "from rtfm.inference_utils import InferenceModel\n",
    "from rtfm.serialization.serializers import get_serializer\n",
    "from rtfm.tokenization.text import prepare_tokenizer\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM, AutoConfig\n",
    "\n",
    "train_config = TrainConfig(model_name=\"mlfoundations/tabula-8b\", context_length=8192)\n",
    "\n",
    "# TODO(jpgard): set add_serializer_tokens to True when using TabuLa-8B\n",
    "tokenizer_config = TokenizerConfig()\n",
    "\n",
    "# Load the configuration\n",
    "config = AutoConfig.from_pretrained(train_config.model_name)\n",
    "\n",
    "# Set the torch_dtype to bfloat16\n",
    "config.torch_dtype = 'bfloat16'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(train_config.model_name, device_map=\"auto\", config=config).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
    "serializer = get_serializer(train_config.serializer_cls)\n",
    "tokenizer, model = prepare_tokenizer(\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    pretrained_model_name_or_path=train_config.model_name,\n",
    "    model_max_length=train_config.context_length,\n",
    "    use_fast_tokenizer=tokenizer_config.use_fast_tokenizer,\n",
    "    serializer_tokens_embed_fn=tokenizer_config.serializer_tokens_embed_fn,\n",
    "    serializer_tokens=serializer.special_tokens\n",
    "    if tokenizer_config.add_serializer_tokens\n",
    "    else None,\n",
    ")\n",
    "\n",
    "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fbaac767622695",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T20:04:39.766837Z",
     "start_time": "2024-06-28T20:04:12.941752Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Column fitness_level is not in target example; got columns Index(['name', 'occupation', 'height_in_meters', 'weight_in_kg', 'bike'], dtype='object'). Adding a dummy placeholder with empty values for preprocessing. This behavior is expected if your target samples do not contain the target column at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction is: excellent\n"
     ]
    }
   ],
   "source": [
    "labeled_examples = pd.DataFrame(\n",
    "    [{\"name\": \"Tadej Pogaƒçar\", \n",
    "      \"occupation\": \"cyclist\",\n",
    "      \"height_in_meters\": 1.76, \n",
    "      \"weight_in_kg\": 66,\n",
    "     \"bike\": \"Colnago V4Rs\",\n",
    "     \"fitness_level\": \"excellent\",\n",
    "     },\n",
    "     {\"name\": \"Josh Gardner\", \n",
    "      \"occupation\": \"student\",\n",
    "      \"height_in_meters\": 1.88, \n",
    "      \"weight_in_kg\": 72,\n",
    "     \"bike\": \"Cannondale Synapse\",\n",
    "     \"fitness_level\": \"good\",\n",
    "     },]\n",
    ")\n",
    "target_example = pd.DataFrame(\n",
    "    [\n",
    "    {\"name\": \"Ludwig Schmidt\", \n",
    "     \"occupation\": \"Assistant professor of computer science\",\n",
    "     \"height_in_meters\": 1.8, \n",
    "     \"weight_in_kg\": 68,\n",
    "     # \"bike\": \"Cervelo\",\n",
    "     \"bike\": \"Colnago V4Rs\",\n",
    "     },\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = inference_model.predict(\n",
    "    target_example=target_example,\n",
    "    target_colname=\"fitness_level\",\n",
    "    target_choices=[\"poor\", \"fair\", \"good\", \"excellent\"],\n",
    "    labeled_examples=labeled_examples,\n",
    "    handle_invalid_predictions=\"warn\",\n",
    ")\n",
    "print(f\"prediction is: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c86babaa9b907",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "list(model.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7419e50-1aab-4afe-a821-5d60422e3b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
